{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26f99ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed975c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "used_cars_data = pd.read_csv(\"final_master_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486d7969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_ AK</th>\n",
       "      <th>State_ AL</th>\n",
       "      <th>State_ AR</th>\n",
       "      <th>State_ AZ</th>\n",
       "      <th>State_ CA</th>\n",
       "      <th>State_ CO</th>\n",
       "      <th>State_ CT</th>\n",
       "      <th>State_ DC</th>\n",
       "      <th>State_ DE</th>\n",
       "      <th>State_ FL</th>\n",
       "      <th>...</th>\n",
       "      <th>City_imporatnce_Medium</th>\n",
       "      <th>State_imporatnce_High</th>\n",
       "      <th>State_imporatnce_Low</th>\n",
       "      <th>State_imporatnce_Medium</th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>City_mean_price</th>\n",
       "      <th>Brand_popularity</th>\n",
       "      <th>Model_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16472</td>\n",
       "      <td>2015</td>\n",
       "      <td>18681</td>\n",
       "      <td>18785.571605</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15749</td>\n",
       "      <td>2015</td>\n",
       "      <td>27592</td>\n",
       "      <td>18233.158996</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16998</td>\n",
       "      <td>2015</td>\n",
       "      <td>13650</td>\n",
       "      <td>22329.498000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15777</td>\n",
       "      <td>2015</td>\n",
       "      <td>25195</td>\n",
       "      <td>19024.911538</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16784</td>\n",
       "      <td>2015</td>\n",
       "      <td>22800</td>\n",
       "      <td>18866.277499</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State_ AK  State_ AL  State_ AR  State_ AZ  State_ CA  State_ CO  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   State_ CT  State_ DC  State_ DE  State_ FL  ...  City_imporatnce_Medium  \\\n",
       "0        0.0        0.0        0.0        0.0  ...                     0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...                     0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...                     0.0   \n",
       "3        0.0        0.0        0.0        0.0  ...                     0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...                     0.0   \n",
       "\n",
       "   State_imporatnce_High  State_imporatnce_Low  State_imporatnce_Medium  \\\n",
       "0                    0.0                   0.0                      1.0   \n",
       "1                    0.0                   0.0                      1.0   \n",
       "2                    1.0                   0.0                      0.0   \n",
       "3                    0.0                   0.0                      1.0   \n",
       "4                    0.0                   0.0                      1.0   \n",
       "\n",
       "   Price  Year  Mileage  City_mean_price  Brand_popularity  Model_level  \n",
       "0  16472  2015    18681     18785.571605                 2            2  \n",
       "1  15749  2015    27592     18233.158996                 2            2  \n",
       "2  16998  2015    13650     22329.498000                 2            2  \n",
       "3  15777  2015    25195     19024.911538                 2            2  \n",
       "4  16784  2015    22800     18866.277499                 2            2  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_cars_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8045c1d",
   "metadata": {},
   "source": [
    "\n",
    "The data is already cleaned and done with feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecb5228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State_ AK           float64\n",
       "State_ AL           float64\n",
       "State_ AR           float64\n",
       "State_ AZ           float64\n",
       "State_ CA           float64\n",
       "                     ...   \n",
       "Year                  int64\n",
       "Mileage               int64\n",
       "City_mean_price     float64\n",
       "Brand_popularity      int64\n",
       "Model_level           int64\n",
       "Length: 66, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_cars_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e457bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Create evaluation function\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Create function to evalyuate models on a few diffferent levels\n",
    "def show_score(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    scores = {\n",
    "              \"Training R^2\" : r2_score(y_train, train_preds),\n",
    "             \"Test R^2\" : r2_score(y_test, test_preds)}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00993d",
   "metadata": {},
   "source": [
    "A pipline consists of steps which contains a list of tuples\n",
    "\n",
    "* Steps we want to do (all in one cell):\n",
    "    !. Build a model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0a9ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6779565148155783"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelling\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import data\n",
    "used_cars_data = pd.read_csv(\"final_master_data.csv\")\n",
    "\n",
    "# Creating a preprocessing and modelling pipeline\n",
    "model = Pipeline(steps = [(\"model\", lgb.LGBMRegressor())])\n",
    "\n",
    "# Split data\n",
    "X = used_cars_data.drop(\"Price\", axis =1)\n",
    "y = used_cars_data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ea75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now let's hyperparameter tune our model\n",
    "# # Use RandomizedSearchCV with our regression Pipeline\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# pipe_grid = {\n",
    "#             'model__n_estimators': [100,200,500,750,1000,2000],\n",
    "#              'model__num_leaves': [40,45,50,55,60,65,70,75,80], \n",
    "#              'model__max_depth':[2,3,4,5,6,7,8,10] ,\n",
    "# #              'model__min_child_samples': [100, 90,200,300,60], \n",
    "# #              'model__min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "#              'model__subsample': [1.0,1,1,1.2,1.8,1.9], \n",
    "# #              'model__colsample_bytree': [0.2,0.4, 0.6, 0.9, 1],\n",
    "# #              'model__reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "# #              'model__reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100],\n",
    "# #              \"model__learning_rate\": [0.1, 0.01, 0.5,1,0.05],\n",
    "#              \"model__objective\": ['regression'],\n",
    "#              'model__boosting': ['gbdt','dart']\n",
    "# }\n",
    "# gs_model = GridSearchCV(model,\n",
    "#                           param_grid= pipe_grid,\n",
    "#                               cv=5,\n",
    "#                               verbose=True)\n",
    "# gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51da57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.679004156824824"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After hyperparameter tuning\n",
    "\n",
    "ideal_model_full = lgb.LGBMRegressor(subsample =1,\n",
    "                                      reg_lambda =  50,\n",
    "                                      reg_alpha = 10,\n",
    "                                      objective = 'regression',\n",
    "                                      num_leaves = 45,\n",
    "                                      n_estimators = 100,\n",
    "                                      min_child_weight = 0.001,\n",
    "                                      min_child_samples = 300,\n",
    "                                      max_depth = 7,\n",
    "                                      learning_rate = 1,\n",
    "                                      colsample_bytree = 0.4,\n",
    "                                      boosting = 'dart')\n",
    "ideal_model_full.fit(X_train, y_train)\n",
    "ideal_model_full.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae1806f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training R^2': 0.6814927207509416, 'Test R^2': 0.679004156824824}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_score(ideal_model_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4d8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our model using pickle\n",
    "\n",
    "import pickle \n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(ideal_model_full, open(\"lightGBM_full_data.pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60018db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model\n",
    "#loaded_pickle_model = pickle.load(open(\"lightGBM_full_data.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d867e5",
   "metadata": {},
   "source": [
    "## Split the data into the new data (After 2006) and old data (before 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd947a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cars that were manufactured before 2006\n",
    "\n",
    "old_data = used_cars_data[used_cars_data[\"Year\"] < 2006]\n",
    "\n",
    "# Cars that were manufactured after 2006\n",
    "new_data = used_cars_data[used_cars_data[\"Year\"]>=2006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a35ab6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31892, 66), (1141956, 66))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data.shape, new_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938bc9a2",
   "metadata": {},
   "source": [
    "## Predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1da2d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668713262736466"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a pipeline\n",
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelling\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Creating a preprocessing and modelling pipeline\n",
    "model = Pipeline(steps = [(\"model\", lgb.LGBMRegressor())])\n",
    "\n",
    "# Split data\n",
    "X = new_data.drop(\"Price\", axis =1)\n",
    "y = new_data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2dff21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training R^2': 0.669140255450589, 'Test R^2': 0.668713262736466}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ab4f7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6696256701138095"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions using hyperparameters\n",
    "ideal_model_new = lgb.LGBMRegressor(subsample =1,\n",
    "                                      reg_lambda =  50,\n",
    "                                      reg_alpha = 10,\n",
    "                                      objective = 'regression',\n",
    "                                      num_leaves = 45,\n",
    "                                      n_estimators = 100,\n",
    "                                      min_child_weight = 0.001,\n",
    "                                      min_child_samples = 300,\n",
    "                                      max_depth = 7,\n",
    "                                      learning_rate = 1,\n",
    "                                      colsample_bytree = 0.4,\n",
    "                                      boosting = 'dart')\n",
    "ideal_model_new.fit(X_train, y_train)\n",
    "ideal_model_new.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c7b3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our model using pickle\n",
    "\n",
    "import pickle \n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(ideal_model_new, open(\"lightGBM_new_data.pkl\", \"wb\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718d76c",
   "metadata": {},
   "source": [
    "## Predictions on old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41badea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6095045414773557"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a pipeline for old data\n",
    "# Getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelling\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Setup random seed \n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Creating a modelling pipeline\n",
    "model = Pipeline(steps = [(\"model\", lgb.LGBMRegressor())])\n",
    "\n",
    "# Split the data\n",
    "X = old_data.drop(\"Price\", axis = 1)\n",
    "y = old_data[\"Price\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Fit the model and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4bfdce",
   "metadata": {},
   "source": [
    "Low score on old data in comparison with new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "684ce898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training R^2': 0.6345118119563075, 'Test R^2': 0.6095045414773557}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa5660c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5953156777803308"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions using hyperparameters\n",
    "ideal_model_old = lgb.LGBMRegressor(subsample =1,\n",
    "                                      reg_lambda =  70,\n",
    "                                      reg_alpha = 0,\n",
    "                                      objective = 'regression',\n",
    "                                      num_leaves =32,\n",
    "                                      n_estimators = 100,\n",
    "                                      min_child_weight = 0.01,\n",
    "                                      min_child_samples = 10,\n",
    "                                      max_depth = 7,\n",
    "                                      learning_rate = 1,\n",
    "                                      colsample_bytree = 0.4,\n",
    "                                      boosting = 'dart',\n",
    "                              )\n",
    "ideal_model_old.fit(X_train, y_train)\n",
    "ideal_model_old.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8d266fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving our model using pickle\n",
    "\n",
    "import pickle \n",
    "\n",
    "# Save an existing model to file\n",
    "pickle.dump(model, open(\"lightGBM_old_data_with_hyperparameter.pkl\", \"wb\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af18294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
